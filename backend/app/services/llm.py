# app/services/llm.py
"""LLM integration â€” OpenAI GPT-4 / Anthropic Claude for document generation."""

import json
from typing import Optional, AsyncGenerator

from app.config import settings


async def generate_text(
    prompt: str,
    system_prompt: str = "You are an HR assistant that generates professional onboarding documents.",
    context: str = "",
    provider: str = "openai",
) -> str:
    """
    Generate text using the configured LLM provider.

    Falls back to a mock response when API keys are not configured.
    """
    if provider == "openai" and settings.OPENAI_API_KEY:
        return await _generate_openai(prompt, system_prompt, context)
    elif provider == "anthropic" and settings.ANTHROPIC_API_KEY:
        return await _generate_anthropic(prompt, system_prompt, context)
    else:
        return _mock_generate(prompt)


async def generate_text_stream(
    prompt: str,
    system_prompt: str = "You are an HR assistant that generates professional onboarding documents.",
    context: str = "",
    provider: str = "openai",
) -> AsyncGenerator[str, None]:
    """
    Stream text generation token-by-token for the Agent Thinking Panel.

    Falls back to mock streaming when API keys are not configured.
    """
    if provider == "openai" and settings.OPENAI_API_KEY:
        async for chunk in _stream_openai(prompt, system_prompt, context):
            yield chunk
    elif provider == "anthropic" and settings.ANTHROPIC_API_KEY:
        async for chunk in _stream_anthropic(prompt, system_prompt, context):
            yield chunk
    else:
        for chunk in _mock_stream(prompt):
            yield chunk


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI implementation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def _generate_openai(prompt: str, system_prompt: str, context: str) -> str:
    """Generate text using OpenAI GPT-4."""
    from openai import OpenAI

    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    messages = [{"role": "system", "content": system_prompt}]
    if context:
        messages.append({"role": "user", "content": f"Reference context:\n{context}"})
    messages.append({"role": "user", "content": prompt})

    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7,
        max_tokens=2000,
    )
    return response.choices[0].message.content or ""


async def _stream_openai(prompt: str, system_prompt: str, context: str) -> AsyncGenerator[str, None]:
    """Stream text from OpenAI."""
    from openai import OpenAI

    client = OpenAI(api_key=settings.OPENAI_API_KEY)

    messages = [{"role": "system", "content": system_prompt}]
    if context:
        messages.append({"role": "user", "content": f"Reference context:\n{context}"})
    messages.append({"role": "user", "content": prompt})

    stream = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7,
        max_tokens=2000,
        stream=True,
    )
    for chunk in stream:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Anthropic implementation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def _generate_anthropic(prompt: str, system_prompt: str, context: str) -> str:
    """Generate text using Anthropic Claude."""
    from anthropic import Anthropic

    client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)

    user_content = prompt
    if context:
        user_content = f"Reference context:\n{context}\n\n{prompt}"

    message = client.messages.create(
        model="claude-3-sonnet-20240229",
        max_tokens=2000,
        system=system_prompt,
        messages=[{"role": "user", "content": user_content}],
    )
    return message.content[0].text


async def _stream_anthropic(prompt: str, system_prompt: str, context: str) -> AsyncGenerator[str, None]:
    """Stream text from Anthropic Claude."""
    from anthropic import Anthropic

    client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)

    user_content = prompt
    if context:
        user_content = f"Reference context:\n{context}\n\n{prompt}"

    with client.messages.stream(
        model="claude-3-sonnet-20240229",
        max_tokens=2000,
        system=system_prompt,
        messages=[{"role": "user", "content": user_content}],
    ) as stream:
        for text in stream.text_stream:
            yield text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mock implementation (for demos / no API keys)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _mock_generate(prompt: str) -> str:
    """Return a mock response for demo/testing without real API keys."""
    prompt_lower = prompt.lower()

    if "welcome email" in prompt_lower:
        return (
            "Subject: Welcome to the Team! ðŸŽ‰\n\n"
            "Dear [Employee Name],\n\n"
            "We're thrilled to welcome you to [Company Name]! Your start date is approaching, "
            "and we want to make sure you have everything you need for a smooth onboarding.\n\n"
            "Here's what to expect on your first day:\n"
            "â€¢ Orientation session at 9:00 AM\n"
            "â€¢ Meet your buddy and manager\n"
            "â€¢ IT setup and equipment collection\n"
            "â€¢ Team lunch\n\n"
            "Please don't hesitate to reach out if you have any questions.\n\n"
            "Best regards,\nHR Team"
        )
    elif "offer letter" in prompt_lower:
        return (
            "OFFER OF EMPLOYMENT\n\n"
            "Dear [Employee Name],\n\n"
            "We are pleased to offer you the position of [Role] in the [Department] department. "
            "Your compensation package includes a competitive salary and comprehensive benefits.\n\n"
            "Start Date: [Start Date]\n"
            "Reporting To: [Manager]\n\n"
            "This offer is contingent upon successful completion of background verification.\n\n"
            "Sincerely,\n[Company Name]"
        )
    elif "30-60-90" in prompt_lower or "plan" in prompt_lower:
        return (
            "30-60-90 DAY PLAN\n\n"
            "FIRST 30 DAYS â€” Learn & Observe\n"
            "â€¢ Complete onboarding training modules\n"
            "â€¢ Meet all team members and key stakeholders\n"
            "â€¢ Understand team processes and tools\n\n"
            "DAYS 31-60 â€” Contribute\n"
            "â€¢ Take ownership of initial tasks\n"
            "â€¢ Attend cross-functional meetings\n"
            "â€¢ Identify areas for improvement\n\n"
            "DAYS 61-90 â€” Lead\n"
            "â€¢ Drive independent projects\n"
            "â€¢ Present learnings to the team\n"
            "â€¢ Set goals for the next quarter"
        )
    elif "equipment" in prompt_lower:
        return (
            "EQUIPMENT REQUEST\n\n"
            "Employee: [Employee Name]\n"
            "Department: [Department]\n"
            "Start Date: [Start Date]\n\n"
            "Required Equipment:\n"
            "â€¢ Laptop (standard configuration)\n"
            "â€¢ Monitor (24\" or 27\")\n"
            "â€¢ Keyboard and mouse\n"
            "â€¢ Headset for meetings\n"
            "â€¢ Access badge\n\n"
            "Software Licenses:\n"
            "â€¢ Email and collaboration suite\n"
            "â€¢ Department-specific tools\n"
            "â€¢ VPN access"
        )
    else:
        return f"[Mock LLM Response]\n\nGenerated content for prompt: {prompt[:100]}..."


def _mock_stream(prompt: str):
    """Yield mock content word-by-word for streaming simulation."""
    response = _mock_generate(prompt)
    words = response.split(" ")
    for word in words:
        yield word + " "
